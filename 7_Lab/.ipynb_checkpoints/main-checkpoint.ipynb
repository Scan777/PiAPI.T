{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73024e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coord {'x_sort': [array([     268.93,      319.36])], 'currentClass': 39}\n",
      "(268, 319) 0\n",
      "30.0 65.0 -90\n",
      "coord {'x_sort': [array([     269.05,      319.35])], 'currentClass': 39}\n",
      "(269, 319) 283\n",
      "53.87190250776544 27.995024513292798 193\n",
      "coord {'x_sort': [array([     268.81,      319.31])], 'currentClass': 39}\n",
      "(268, 319) 283\n",
      "54.339979027525544 27.995024513292798 193\n",
      "coord {'x_sort': [array([     279.06,      270.32]), array([     378.92,      320.39])], 'currentClass': 39}\n",
      "(279, 270) 0\n",
      "30.0 65.0 -90\n",
      "coord {'x_sort': [array([     378.64,      320.76])], 'currentClass': 39}\n",
      "(378, 320) 281\n",
      "3.0434236075963987 27.791436733856152 191\n",
      "coord {'x_sort': [array([     378.87,      320.73])], 'currentClass': 39}\n",
      "(378, 320) 281\n",
      "3.0434236075963987 27.791436733856152 191\n",
      "coord {'x_sort': [array([     378.88,      320.75])], 'currentClass': 39}\n",
      "(378, 320) 281\n",
      "3.0434236075963987 27.791436733856152 191\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 59>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     76\u001b[0m childThread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m#ret, frame = cap.read()\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     success, depth_colormap, frame, depth \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     coord \u001b[38;5;241m=\u001b[39m detector\u001b[38;5;241m.\u001b[39mdetect(frame, model) \n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m coord[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_sort\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m!=\u001b[39m[] \u001b[38;5;129;01mand\u001b[39;00m dataQueue\u001b[38;5;241m.\u001b[39mempty()\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32m~\\ПиПАИ.Т\\7_Lab\\realsense_camera.py:51\u001b[0m, in \u001b[0;36mRealsenseCamera.get_frame_stream\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     48\u001b[0m spatial\u001b[38;5;241m.\u001b[39mset_option(rs\u001b[38;5;241m.\u001b[39moption\u001b[38;5;241m.\u001b[39mholes_fill, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     49\u001b[0m filtered_depth \u001b[38;5;241m=\u001b[39m spatial\u001b[38;5;241m.\u001b[39mprocess(depth_frame)\n\u001b[1;32m---> 51\u001b[0m hole_filling \u001b[38;5;241m=\u001b[39m \u001b[43mrs\u001b[49m\u001b[38;5;241m.\u001b[39mhole_filling_filter()\n\u001b[0;32m     52\u001b[0m filled_depth \u001b[38;5;241m=\u001b[39m hole_filling\u001b[38;5;241m.\u001b[39mprocess(filtered_depth)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Create colormap to show the depth of the Objects\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import queue\n",
    "import threading\n",
    "import pyrealsense2\n",
    "from realsense_camera import *\n",
    "import cv2\n",
    "import time\n",
    "from ObjectDetector import ObjectDetector\n",
    "from ObjectDetector import Robot_mm\n",
    "from kuka import Kuka\n",
    "from openshowvar import *\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "import numpy as np\n",
    "\n",
    "print('go')\n",
    "robot = openshowvar(ip = '192.168.17.2', port = 7000)\n",
    "kuka = Kuka(robot)\n",
    "\n",
    "kuka.read_cartesian()\n",
    "\n",
    "kuka.set_base(8)\n",
    "kuka.set_tool(10)\n",
    "\n",
    "# Set speed (%)\n",
    "kuka.set_speed(100)\n",
    "print('ready')\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Function to clear the queue\n",
    "def clearQueue(dataQueue):\n",
    "    while not dataQueue.empty():\n",
    "        dataQueue.get()\n",
    "\n",
    "# Function for the child thread to process coordinates\n",
    "def childProcess(stopEvent, dataQueue):\n",
    "    while not stopEvent.is_set():\n",
    "        try:\n",
    "            coord = dataQueue.get(timeout=1)     \n",
    "        except queue.Empty:\n",
    "            continue\n",
    "        while True:\n",
    "            if coord!=None:\n",
    "                print(\"coord\", coord)\n",
    "                Robot.Kuka_move(kuka, depth, coord['x_sort'][0])\n",
    "                time.sleep(2)\n",
    "                Robot.Kuka_base(kuka) \n",
    "                clearQueue(dataQueue)\n",
    "                break\n",
    "            else:\n",
    "                #Robot.Kuka_base(kuka) \n",
    "                clearQueue(dataQueue)\n",
    "                break\n",
    "            break\n",
    "        clearQueue(dataQueue)\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Open the video capture device\n",
    "    #cap = cv2.VideoCapture(1)  \n",
    "    cap = RealsenseCamera()\n",
    "    # Create an instance of ObjectDetector\n",
    "    detector = ObjectDetector()\n",
    "    Robot=Robot_mm()\n",
    "    # Create an Event object to signal the child thread to stop\n",
    "    stopEvent = threading.Event()\n",
    "    # Create a queue to communicate coordinates between threads\n",
    "    dataQueue = queue.Queue()\n",
    "    coord = None\n",
    "    #dataQueue.put(coord)\n",
    "    # Create the child thread\n",
    "    childThread = threading.Thread(target=childProcess, args=(stopEvent, dataQueue,))\n",
    "    # Start the child thread\n",
    "    Robot.Kuka_base(kuka) \n",
    "    childThread.start()\n",
    "    while True:\n",
    "        #ret, frame = cap.read()\n",
    "        success, depth_colormap, frame, depth = cap.get_frame_stream()\n",
    "        coord = detector.detect(frame, model) \n",
    "        if coord['x_sort']!=[] and dataQueue.empty()==True:\n",
    "            dataQueue.put(coord)  \n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "               \n",
    "        # Check for the 'q' key press to stop the program\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"q\"):\n",
    "            stopEvent.set()\n",
    "            break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a587d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
